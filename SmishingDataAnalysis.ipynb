{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jorge-pais/KUL-MachineLearning/blob/main/SmishingDataAnalysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SMS Smishing Detection - Machine Learning Project\n",
        "\n",
        "## Data Analysis"
      ],
      "metadata": {
        "id": "XegDNXVcT-Lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rhr7ZSTDVYAw",
        "outputId": "1396cc31-9645-4b27-e18a-2f94b19b56f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vMzQ83LsT8bq",
        "outputId": "06cc3b07-a3bb-49b3-a30a-9ffe029abfd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      LABEL                                               TEXT URL EMAIL PHONE\n",
              "0       ham  Your opinion about me? 1. Over 2. Jada 3. Kusr...  No    No    No\n",
              "1       ham  What's up? Do you want me to come online? If y...  No    No    No\n",
              "2       ham                       So u workin overtime nigpun?  No    No    No\n",
              "3       ham  Also sir, i sent you an email about how to log...  No    No    No\n",
              "4  Smishing  Please Stay At Home. To encourage the notion o...  No    No    No"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0b06d6c7-ee10-4f5d-94e5-3f7c32d8c78d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>LABEL</th>\n",
              "      <th>TEXT</th>\n",
              "      <th>URL</th>\n",
              "      <th>EMAIL</th>\n",
              "      <th>PHONE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Your opinion about me? 1. Over 2. Jada 3. Kusr...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>What's up? Do you want me to come online? If y...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ham</td>\n",
              "      <td>So u workin overtime nigpun?</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>Also sir, i sent you an email about how to log...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Smishing</td>\n",
              "      <td>Please Stay At Home. To encourage the notion o...</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0b06d6c7-ee10-4f5d-94e5-3f7c32d8c78d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0b06d6c7-ee10-4f5d-94e5-3f7c32d8c78d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0b06d6c7-ee10-4f5d-94e5-3f7c32d8c78d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-5cad0bf5-608f-4b56-9b0a-770f37bcdefb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5cad0bf5-608f-4b56-9b0a-770f37bcdefb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-5cad0bf5-608f-4b56-9b0a-770f37bcdefb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "DATA_PATH = Path.cwd()/\"drive\"/\"MyDrive\"/\"ML\"/\"dataset\";\n",
        "\n",
        "# Read the dataset from csv file\n",
        "dataset = pd.read_csv(DATA_PATH/\"Dataset_5971.csv\")\n",
        "\n",
        "# Seperate the dataset into labels and features\n",
        "\n",
        "# Some of the data is mislabeled (there are examples with both label \"Spam\" and \"spam\" for example)\n",
        "y = dataset[\"LABEL\"].str.lower() # Labels\n",
        "\n",
        "X = dataset.loc[:, dataset.columns != \"LABEL\"].copy() # Features\n",
        "\n",
        "# there is probably a better way to do this\n",
        "for col in X.columns:\n",
        "    if col != 'TEXT':\n",
        "        X[col] = X[col].str.lower()\n",
        "\n",
        "np.testing.assert_array_equal(y.index.values, X.index.values);\n",
        "\n",
        "dataset.head()\n",
        "#dataset.loc[:20, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Characteristics of the dataset\n",
        "\n",
        "Now we can take a look at the characteristics of our dataset. We will take a look at the amount of entries, if there is any missing data and the amount of unique data in every column. And lastly we will take a look at the proportion of the labels in our dataset.\n",
        "\n",
        "There are 5971 entries within the dataset. Which sufficies the project requirements. Also there is no missing data in the dataset and we have enough unique **TEXT** data\n",
        "\n",
        "It becomes clear that this dataset is quite unbalanced, and as such we should take this into account wihtin our machine learning model."
      ],
      "metadata": {
        "id": "j6LKRxd7dSgN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of rows and columns\n",
        "num_rows, num_cols = dataset.shape\n",
        "print(\"\\033[1mNumber of rows:\\033[0m\", num_rows)\n",
        "print(\"\\033[1mNumber of columns:\\033[0m\", num_cols)\n",
        "\n",
        "# Missing values\n",
        "missing_values = dataset.isnull().sum()\n",
        "print(\"\\033[1mMissing values:\\033[0m\")\n",
        "print(missing_values)\n",
        "\n",
        "# Number of unique values in each column\n",
        "unique_values = dataset.nunique()\n",
        "print(\"\\033[1mNumber of unique values in each column:\\033[0m\")\n",
        "print(unique_values)\n",
        "\n",
        "n_obvs = y.shape[0]\n",
        "label_count = y.value_counts()\n",
        "bars = label_count.plot(kind='bar', color=['blue', 'purple', 'red'])\n",
        "plt.title('Label Frequencies in the Dataset')\n",
        "plt.xlabel('Labels')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "for bar in bars.patches:\n",
        "    plt.annotate(format(bar.get_height(), '.0f'),\n",
        "                 (bar.get_x() + bar.get_width() / 2,\n",
        "                  bar.get_height()), ha='center', va='center',\n",
        "                 size=10, xytext=(0, 8),\n",
        "                 textcoords='offset points')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 789
        },
        "id": "YLjO5VqOYgEt",
        "outputId": "db1acd18-78eb-4625-a952-5fb8f7f332c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1mNumber of rows:\u001b[0m 5971\n",
            "\u001b[1mNumber of columns:\u001b[0m 5\n",
            "\u001b[1mMissing values:\u001b[0m\n",
            "LABEL    0\n",
            "TEXT     0\n",
            "URL      0\n",
            "EMAIL    0\n",
            "PHONE    0\n",
            "dtype: int64\n",
            "\u001b[1mNumber of unique values in each column:\u001b[0m\n",
            "LABEL       5\n",
            "TEXT     5949\n",
            "URL         2\n",
            "EMAIL       2\n",
            "PHONE       2\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to deal with unbalanced data:\n",
        "\n",
        "- *Oversampling*: Involves adding more examples from the minority class\n",
        "- *Undersampling*: Involves removing examples from the majority class\n",
        "- *Penalized Models*: These impose an additional cost on the model for making classification mistakes on the minority class during training (for example, many scikit-learn models accept a `class_weights` parameters, which may be set to `class_weights='balanced'` in order to account for this)\n",
        "- *Data augmentation*: This technique is especially useful when dealing with datasets like images where new data can be created by cropping, rotating, flipping, etc.\n",
        "\n",
        "It is important to point out that this should be done before training and ***data splitting***:"
      ],
      "metadata": {
        "id": "GKr6mDERS7pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "# Lectures advised reserving 20-40% of your data set for testing.\n",
        "TEST_SIZE = 0.3\n",
        "\n",
        "# the stratify parameters makes it such that in the split the class labels are\n",
        "# roughly the same proportion as in the original data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, stratify=y, random_state=1337)\n",
        "print(\"X_train.shape\", X_train.shape, \"y_train.shape\", y_train.shape)\n",
        "print(\"X_test.shape\", X_test.shape, \"y_test.shape\", y_test.shape)\n",
        "\n",
        "\"\"\"split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
        "\n",
        "for train_index, val_index in split.split(X, y):\n",
        "   X_train, X_val = X[train_index], X[val_index]\n",
        "   y_train, y_val = y[train_index], y[val_index]\n",
        "\"\"\";"
      ],
      "metadata": {
        "id": "-P_7Op9JcyPB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a4719b3-38a2-477d-82b1-cac128afc7a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape (4179, 4) y_train.shape (4179,)\n",
            "X_test.shape (1792, 4) y_test.shape (1792,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text datapreprocessing\n",
        "\n",
        "1. Text Cleaning: This is the initial step in text preprocessing, which involves removing unnecessary and redundant data\n",
        "\n",
        "2. Tokenization: This step involves splitting the text into individual words or tokens.\n",
        "\n",
        "3. Stopword Removal: Stopwords are the most common words in a language like 'the', 'is', 'in', 'for', etc.\n",
        "\n",
        "4. Stemming/Lemmatization: These techniques are used to reduce a word to its root form.\n",
        "\n",
        "5. Vectorization: After preprocessing, the text data needs to be converted into numerical form for the machine learning model."
      ],
      "metadata": {
        "id": "Zf_aROKfYOLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import re\n",
        "\n",
        "class TextPreprocessing(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        X_transformed = []\n",
        "        for text in X:\n",
        "            text = re.sub(r'\\d+', '', text)\n",
        "            text = re.sub(r'\\W+', ' ', text)\n",
        "            text = text.lower()\n",
        "\n",
        "            # there is no need for tokenization, the vectorizer handles this for us\n",
        "            # words = word_tokenize(text)\n",
        "            # words = [self.lemmatizer.lemmatize(word) for word in words if word not in self.stop_words]\n",
        "            X_transformed.append(text)\n",
        "\n",
        "        return X_transformed"
      ],
      "metadata": {
        "id": "rjuHKUD8Y2ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do this if nltk complains about downloading something\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8FKGkTSf9Q2",
        "outputId": "eb68e23f-e797-4cb4-bc3a-74c47e89a65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment Models\n",
        "\n",
        "For the classification model based on the assignment code, we've decided to utilize the logistic regression, and implement it into a sklearn compatible class.\n",
        "\n",
        "To do multiclass classification we can implement a one-vs-all strategy in the pipeline using a `OneVsRestClassifier`."
      ],
      "metadata": {
        "id": "MiRNc1ZynGnj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Logistic Classifier (assignment 2)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "class LogisticClassifier(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, lambda_=1, iter_=1000, learning_rate_=0.01):\n",
        "        self.lambda_ = lambda_\n",
        "        self.iter_ = iter_\n",
        "        self.learning_rate_ = learning_rate_\n",
        "        self.w = None\n",
        "        self.b = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        z = np.dot(X, self.w) + self.b\n",
        "        f = self.sigmoid(z)\n",
        "        return (f > 0.5).astype(int)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        m, n = X.shape\n",
        "\n",
        "        print(X.shape)\n",
        "\n",
        "        self.w = np.zeros((n, 1))\n",
        "        self.b = 0\n",
        "\n",
        "        # Gradient descent\n",
        "        for _ in range(self.iter_):  # number of iterations\n",
        "            dj_db, dj_dw = self.compute_gradient_reg(X, y, self.w, self.b, self.lambda_)\n",
        "            self.w = self.w - self.learning_rate_ * dj_dw\n",
        "            self.b = self.b - self.learning_rate_ * dj_db\n",
        "\n",
        "        return self\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        \"\"\"\n",
        "        Compute the sigmoid of z\n",
        "\n",
        "        Args:\n",
        "            z (ndarray): A scalar, numpy array of any size.\n",
        "\n",
        "        Returns:\n",
        "            g (ndarray): sigmoid(z), with the same shape as z\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        ### START CODE HERE ###\n",
        "        g = 1/(1+np.power(np.e, -z))\n",
        "        ### END SOLUTION ###\n",
        "\n",
        "        return g\n",
        "\n",
        "    def compute_cost(self, X, y, w, b, lambda_= 1):\n",
        "        \"\"\"\n",
        "        Computes the cost over all examples\n",
        "        Args:\n",
        "        X : (ndarray Shape (m,n)) data, m examples by n features\n",
        "        y : (array_like Shape (m,)) target value\n",
        "        w : (array_like Shape (n,)) Values of parameters of the model\n",
        "        b : scalar Values of bias parameter of the model\n",
        "        lambda_: unused placeholder\n",
        "        Returns:\n",
        "        total_cost: (scalar)         cost\n",
        "        \"\"\"\n",
        "\n",
        "        m, n = X.shape\n",
        "\n",
        "        ### START CODE HERE ###\n",
        "\n",
        "        z = np.dot(X, w) + b\n",
        "\n",
        "        f = self.sigmoid(z)\n",
        "\n",
        "        loss = (np.multiply(-y, np.log(f))) - (np.multiply((1 - y), np.log(1 - f)))\n",
        "\n",
        "        total_cost = 1/m * np.sum(loss)\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return total_cost\n",
        "\n",
        "    def compute_cost_reg(self, X, y, w, b, lambda_ = 1):\n",
        "        \"\"\"\n",
        "        Computes the cost over all examples\n",
        "        Args:\n",
        "        X : (array_like Shape (m,n)) data, m examples by n features\n",
        "        y : (array_like Shape (m,)) target value\n",
        "        w : (array_like Shape (n,)) Values of parameters of the model\n",
        "        b : (array_like Shape (n,)) Values of bias parameter of the model\n",
        "        lambda_ : (scalar, float)    Controls amount of regularization\n",
        "        Returns:\n",
        "        total_cost: (scalar)         cost\n",
        "        \"\"\"\n",
        "\n",
        "        m, n = X.shape\n",
        "\n",
        "        # Calls the compute_cost function that you implemented above\n",
        "        cost_without_reg = self.compute_cost(X, y, w, b)\n",
        "\n",
        "        # You need to calculate this value\n",
        "        reg_cost = 0.\n",
        "\n",
        "        ### START CODE HERE ###\n",
        "\n",
        "        reg_cost = np.sum(np.power(w,2))\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        # Add the regularization cost to get the total cost\n",
        "        total_cost = cost_without_reg + (lambda_/(2 * m)) * reg_cost\n",
        "\n",
        "        return total_cost\n",
        "\n",
        "    def compute_gradient(self, X, y, w, b, lambda_=None):\n",
        "        \"\"\"\n",
        "        Computes the gradient for logistic regression\n",
        "\n",
        "        Args:\n",
        "        X : (ndarray Shape (m,n)) variable such as house size\n",
        "        y : (array_like Shape (m,1)) actual value\n",
        "        w : (array_like Shape (n,1)) values of parameters of the model\n",
        "        b : (scalar)                 value of parameter of the model\n",
        "        lambda_: unused placeholder.\n",
        "        Returns\n",
        "        dj_dw: (array_like Shape (n,1)) The gradient of the cost w.r.t. the parameters w.\n",
        "        dj_db: (scalar)                The gradient of the cost w.r.t. the parameter b.\n",
        "        \"\"\"\n",
        "        m, n = X.shape\n",
        "        dj_dw = np.zeros(w.shape)\n",
        "        dj_db = 0.\n",
        "\n",
        "        ### START CODE HERE ###\n",
        "        z = np.dot(X, w) + b\n",
        "        f = self.sigmoid(z)\n",
        "\n",
        "        dj_db = 1/m * np.sum(f - y)\n",
        "        dj_dw = 1/m * np.dot((f - y), X)\n",
        "        #dj_dw = 1/m * np.sum(, axis = 0)\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "\n",
        "        return dj_db, dj_dw\n",
        "\n",
        "    def compute_gradient_reg(self, X, y, w, b, lambda_ = 1):\n",
        "        \"\"\"\n",
        "        Computes the gradient for linear regression\n",
        "\n",
        "        Args:\n",
        "        X : (ndarray Shape (m,n))   variable such as house size\n",
        "        y : (ndarray Shape (m,))    actual value\n",
        "        w : (ndarray Shape (n,))    values of parameters of the model\n",
        "        b : (scalar)                value of parameter of the model\n",
        "        lambda_ : (scalar,float)    regularization constant\n",
        "        Returns\n",
        "        dj_db: (scalar)             The gradient of the cost w.r.t. the parameter b.\n",
        "        dj_dw: (ndarray Shape (n,)) The gradient of the cost w.r.t. the parameters w.\n",
        "\n",
        "        \"\"\"\n",
        "        m, n = X.shape\n",
        "\n",
        "        dj_db, dj_dw = self.compute_gradient(X, y, w, b)\n",
        "\n",
        "        ### START CODE HERE ###\n",
        "\n",
        "        dj_dw = (dj_dw + (lambda_/m * w))\n",
        "\n",
        "        ### END CODE HERE ###\n",
        "\n",
        "        return dj_db, dj_dw\n"
      ],
      "metadata": {
        "id": "1syoyrNsmmTx",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model\n",
        "\n",
        "SKLearn offers a very easy to use way to chain different machine learning model steps within a pipeline.\n",
        "\n",
        "Where we use the `ColumnTransformer` which allows us to apply preprocessing to just a single column. Which in this case is needed for the email body, as well as the categorical features.\n",
        "\n",
        "## Models\n",
        "\n"
      ],
      "metadata": {
        "id": "--ihie28FZ_7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OrdinalEncoder, FunctionTransformer\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('dataProcessing', ColumnTransformer([\n",
        "        ('text_preprocess', Pipeline([\n",
        "            ('textPreprocessing', TextPreprocessing()),\n",
        "            ('vectorizer', TfidfVectorizer())\n",
        "        ]), \"TEXT\"),\n",
        "        ('encoding', OrdinalEncoder(), X.columns != \"TEXT\")\n",
        "    ])),\n",
        "    #('todense', FunctionTransformer(lambda x: x.toarray(), accept_sparse = True)), # For naive bayes classifiers\n",
        "    #('classifier', OneVsRestClassifier(GaussianNB()))\n",
        "    #('classifier', OneVsRestClassifier(MultinomialNB()))\n",
        "    #('classifier', RandomForestClassifier(n_estimators = 20))\n",
        "    #('classifier', SVC(class_weight='balanced', probability=True))\n",
        "    ('classifier', OneVsRestClassifier(LogisticRegression(class_weight='balanced', C=1/100)))\n",
        "    # ('classifier', OneVsRestClassifier(LogisticClassifier(iter_=10)))\n",
        "])"
      ],
      "metadata": {
        "id": "GpgFTbejcq2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now fit the model !\n",
        "pipeline.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "Ygb__ttWcs3X",
        "outputId": "4c953dec-bb4c-4621-89bd-a56af2f0b97a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('dataProcessing',\n",
              "                 ColumnTransformer(transformers=[('text_preprocess',\n",
              "                                                  Pipeline(steps=[('textPreprocessing',\n",
              "                                                                   TextPreprocessing()),\n",
              "                                                                  ('vectorizer',\n",
              "                                                                   TfidfVectorizer())]),\n",
              "                                                  'TEXT'),\n",
              "                                                 ('encoding', OrdinalEncoder(),\n",
              "                                                  array([False,  True,  True,  True]))])),\n",
              "                ('classifier',\n",
              "                 OneVsRestClassifier(estimator=LogisticRegression(C=0.01,\n",
              "                                                                  class_weight='balanced')))])"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;dataProcessing&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;text_preprocess&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;textPreprocessing&#x27;,\n",
              "                                                                   TextPreprocessing()),\n",
              "                                                                  (&#x27;vectorizer&#x27;,\n",
              "                                                                   TfidfVectorizer())]),\n",
              "                                                  &#x27;TEXT&#x27;),\n",
              "                                                 (&#x27;encoding&#x27;, OrdinalEncoder(),\n",
              "                                                  array([False,  True,  True,  True]))])),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 OneVsRestClassifier(estimator=LogisticRegression(C=0.01,\n",
              "                                                                  class_weight=&#x27;balanced&#x27;)))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;dataProcessing&#x27;,\n",
              "                 ColumnTransformer(transformers=[(&#x27;text_preprocess&#x27;,\n",
              "                                                  Pipeline(steps=[(&#x27;textPreprocessing&#x27;,\n",
              "                                                                   TextPreprocessing()),\n",
              "                                                                  (&#x27;vectorizer&#x27;,\n",
              "                                                                   TfidfVectorizer())]),\n",
              "                                                  &#x27;TEXT&#x27;),\n",
              "                                                 (&#x27;encoding&#x27;, OrdinalEncoder(),\n",
              "                                                  array([False,  True,  True,  True]))])),\n",
              "                (&#x27;classifier&#x27;,\n",
              "                 OneVsRestClassifier(estimator=LogisticRegression(C=0.01,\n",
              "                                                                  class_weight=&#x27;balanced&#x27;)))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">dataProcessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;text_preprocess&#x27;,\n",
              "                                 Pipeline(steps=[(&#x27;textPreprocessing&#x27;,\n",
              "                                                  TextPreprocessing()),\n",
              "                                                 (&#x27;vectorizer&#x27;,\n",
              "                                                  TfidfVectorizer())]),\n",
              "                                 &#x27;TEXT&#x27;),\n",
              "                                (&#x27;encoding&#x27;, OrdinalEncoder(),\n",
              "                                 array([False,  True,  True,  True]))])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">text_preprocess</label><div class=\"sk-toggleable__content\"><pre>TEXT</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TextPreprocessing</label><div class=\"sk-toggleable__content\"><pre>TextPreprocessing()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">encoding</label><div class=\"sk-toggleable__content\"><pre>[False  True  True  True]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OrdinalEncoder</label><div class=\"sk-toggleable__content\"><pre>OrdinalEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">classifier: OneVsRestClassifier</label><div class=\"sk-toggleable__content\"><pre>OneVsRestClassifier(estimator=LogisticRegression(C=0.01,\n",
              "                                                 class_weight=&#x27;balanced&#x27;))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, class_weight=&#x27;balanced&#x27;)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, class_weight=&#x27;balanced&#x27;)</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model validation and performance metrics\n",
        "\n",
        "Now we run the test/validation set through the trained model and measure the accuracy of the model"
      ],
      "metadata": {
        "id": "EMSWhJJxI3oV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, average_precision_score, roc_auc_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "predictions = pipeline.predict(X_test)\n",
        "prediction_prob = pipeline.predict_proba(X_test)\n",
        "#prediction_prob += 1e-9; prediction_prob = np.nan_to_num(prediction_prob) # for naive bayes\n",
        "\n",
        "print(\"Accuracy: \" + str(accuracy_score(y_test, predictions)))\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "y_test_bin = lb.fit_transform(y_test)\n",
        "print(prediction_prob)\n",
        "print(roc_auc_score(y_test_bin, prediction_prob))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jaSmegSeKkj",
        "outputId": "227b7b3b-5654-4250-cf63-a8a305381a6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9129464285714286\n",
            "[[0.56892911 0.17865    0.25242089]\n",
            " [0.58177442 0.18021851 0.23800707]\n",
            " [0.55395531 0.19502379 0.2510209 ]\n",
            " ...\n",
            " [0.57630227 0.18001258 0.24368516]\n",
            " [0.10731839 0.46126538 0.43141623]\n",
            " [0.57908113 0.17988958 0.24102928]]\n",
            "0.966335026267935\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Neural Network for Multiclass Classification"
      ],
      "metadata": {
        "id": "YSh-vlHXyqh0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten\n",
        "from tensorflow.keras.layers import Dense\n"
      ],
      "metadata": {
        "id": "mINpIBLbEMeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = dataset['TEXT'].tolist()\n",
        "labels = dataset['LABEL'].tolist()\n",
        "url_features = dataset['URL'].tolist()\n",
        "email_features = dataset['EMAIL'].tolist()\n",
        "phone_features = dataset['PHONE'].tolist()\n",
        "\n",
        "combined_features = [f\"{text} {url} {email} {phone}\" for text, url, email, phone in zip(texts, url_features, email_features, phone_features)]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "labels_encoded = label_encoder.fit_transform(labels)\n",
        "labels_onehot = to_categorical(labels_encoded)\n",
        "\n",
        "# # # Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(combined_features, labels_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Text preprocessing\n",
        "text_preprocessor = TextPreprocessing()\n",
        "X_train_transformed = text_preprocessor.fit_transform(X_train)\n",
        "X_test_transformed = text_preprocessor.transform(X_test)\n",
        "\n",
        "# Tokenize and pad sequences\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X_train_transformed)\n",
        "X_train_sequences = tokenizer.texts_to_sequences(X_train_transformed)\n",
        "X_test_sequences = tokenizer.texts_to_sequences(X_test_transformed)\n",
        "\n",
        "max_length = 100  # Adjust as needed\n",
        "X_train_padded = pad_sequences(X_train_sequences, maxlen=max_length)\n",
        "X_test_padded = pad_sequences(X_test_sequences, maxlen=max_length)\n",
        "\n",
        "print(X_train_padded.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "# Build and train the neural network\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 16  # Adjust as needed\n",
        "\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "    Flatten(),\n",
        "    Dense(units=15, activation='relu'),\n",
        "    #Dense(units=20, activation='relu'),\n",
        "    Dense(units=num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train_padded, y_train, epochs=100, validation_data=(X_test_padded, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQUuuBF6AVRS",
        "outputId": "8cf24ec1-82f0-411a-fc6c-b998c659c248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4776, 100)\n",
            "(4776, 5)\n",
            "Epoch 1/100\n",
            "150/150 [==============================] - 11s 71ms/step - loss: 0.6745 - accuracy: 0.8032 - val_loss: 0.4121 - val_accuracy: 0.8636\n",
            "Epoch 2/100\n",
            "150/150 [==============================] - 4s 25ms/step - loss: 0.2938 - accuracy: 0.8928 - val_loss: 0.2425 - val_accuracy: 0.9088\n",
            "Epoch 3/100\n",
            "150/150 [==============================] - 2s 12ms/step - loss: 0.1746 - accuracy: 0.9382 - val_loss: 0.2011 - val_accuracy: 0.9372\n",
            "Epoch 4/100\n",
            "150/150 [==============================] - 1s 10ms/step - loss: 0.1281 - accuracy: 0.9611 - val_loss: 0.1896 - val_accuracy: 0.9414\n",
            "Epoch 5/100\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.1001 - accuracy: 0.9717 - val_loss: 0.1866 - val_accuracy: 0.9397\n",
            "Epoch 6/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0807 - accuracy: 0.9797 - val_loss: 0.1950 - val_accuracy: 0.9372\n",
            "Epoch 7/100\n",
            "150/150 [==============================] - 2s 10ms/step - loss: 0.0694 - accuracy: 0.9820 - val_loss: 0.1890 - val_accuracy: 0.9439\n",
            "Epoch 8/100\n",
            "150/150 [==============================] - 2s 15ms/step - loss: 0.0606 - accuracy: 0.9847 - val_loss: 0.1970 - val_accuracy: 0.9397\n",
            "Epoch 9/100\n",
            "150/150 [==============================] - 1s 10ms/step - loss: 0.0554 - accuracy: 0.9843 - val_loss: 0.2000 - val_accuracy: 0.9397\n",
            "Epoch 10/100\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.0511 - accuracy: 0.9845 - val_loss: 0.2068 - val_accuracy: 0.9439\n",
            "Epoch 11/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0472 - accuracy: 0.9851 - val_loss: 0.2100 - val_accuracy: 0.9431\n",
            "Epoch 12/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0443 - accuracy: 0.9858 - val_loss: 0.2193 - val_accuracy: 0.9389\n",
            "Epoch 13/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0429 - accuracy: 0.9860 - val_loss: 0.2312 - val_accuracy: 0.9431\n",
            "Epoch 14/100\n",
            "150/150 [==============================] - 1s 9ms/step - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.2260 - val_accuracy: 0.9456\n",
            "Epoch 15/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0381 - accuracy: 0.9868 - val_loss: 0.2370 - val_accuracy: 0.9456\n",
            "Epoch 16/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9864 - val_loss: 0.2417 - val_accuracy: 0.9464\n",
            "Epoch 17/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0365 - accuracy: 0.9853 - val_loss: 0.2441 - val_accuracy: 0.9439\n",
            "Epoch 18/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0351 - accuracy: 0.9868 - val_loss: 0.2456 - val_accuracy: 0.9456\n",
            "Epoch 19/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0348 - accuracy: 0.9860 - val_loss: 0.2570 - val_accuracy: 0.9439\n",
            "Epoch 20/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0336 - accuracy: 0.9870 - val_loss: 0.2607 - val_accuracy: 0.9473\n",
            "Epoch 21/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9866 - val_loss: 0.2530 - val_accuracy: 0.9423\n",
            "Epoch 22/100\n",
            "150/150 [==============================] - 1s 9ms/step - loss: 0.0319 - accuracy: 0.9866 - val_loss: 0.2636 - val_accuracy: 0.9473\n",
            "Epoch 23/100\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.0317 - accuracy: 0.9864 - val_loss: 0.2753 - val_accuracy: 0.9456\n",
            "Epoch 24/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9866 - val_loss: 0.2856 - val_accuracy: 0.9473\n",
            "Epoch 25/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0293 - accuracy: 0.9872 - val_loss: 0.2837 - val_accuracy: 0.9431\n",
            "Epoch 26/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0289 - accuracy: 0.9872 - val_loss: 0.2768 - val_accuracy: 0.9439\n",
            "Epoch 27/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0283 - accuracy: 0.9868 - val_loss: 0.2861 - val_accuracy: 0.9490\n",
            "Epoch 28/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9870 - val_loss: 0.2841 - val_accuracy: 0.9473\n",
            "Epoch 29/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0270 - accuracy: 0.9868 - val_loss: 0.2850 - val_accuracy: 0.9423\n",
            "Epoch 30/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0284 - accuracy: 0.9866 - val_loss: 0.2932 - val_accuracy: 0.9464\n",
            "Epoch 31/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0260 - accuracy: 0.9876 - val_loss: 0.3071 - val_accuracy: 0.9448\n",
            "Epoch 32/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9864 - val_loss: 0.3016 - val_accuracy: 0.9448\n",
            "Epoch 33/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0248 - accuracy: 0.9874 - val_loss: 0.3027 - val_accuracy: 0.9423\n",
            "Epoch 34/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0250 - accuracy: 0.9862 - val_loss: 0.3149 - val_accuracy: 0.9481\n",
            "Epoch 35/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0245 - accuracy: 0.9870 - val_loss: 0.3073 - val_accuracy: 0.9423\n",
            "Epoch 36/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0243 - accuracy: 0.9879 - val_loss: 0.3152 - val_accuracy: 0.9464\n",
            "Epoch 37/100\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.0232 - accuracy: 0.9881 - val_loss: 0.3273 - val_accuracy: 0.9464\n",
            "Epoch 38/100\n",
            "150/150 [==============================] - 2s 10ms/step - loss: 0.0243 - accuracy: 0.9883 - val_loss: 0.3103 - val_accuracy: 0.9456\n",
            "Epoch 39/100\n",
            "150/150 [==============================] - 2s 15ms/step - loss: 0.0228 - accuracy: 0.9893 - val_loss: 0.3176 - val_accuracy: 0.9473\n",
            "Epoch 40/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0222 - accuracy: 0.9887 - val_loss: 0.3253 - val_accuracy: 0.9439\n",
            "Epoch 41/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0212 - accuracy: 0.9887 - val_loss: 0.3291 - val_accuracy: 0.9481\n",
            "Epoch 42/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0218 - accuracy: 0.9887 - val_loss: 0.3317 - val_accuracy: 0.9473\n",
            "Epoch 43/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0200 - accuracy: 0.9899 - val_loss: 0.3358 - val_accuracy: 0.9481\n",
            "Epoch 44/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0201 - accuracy: 0.9902 - val_loss: 0.3320 - val_accuracy: 0.9464\n",
            "Epoch 45/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0192 - accuracy: 0.9899 - val_loss: 0.3426 - val_accuracy: 0.9464\n",
            "Epoch 46/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0182 - accuracy: 0.9893 - val_loss: 0.3418 - val_accuracy: 0.9490\n",
            "Epoch 47/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0185 - accuracy: 0.9904 - val_loss: 0.3379 - val_accuracy: 0.9456\n",
            "Epoch 48/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0176 - accuracy: 0.9906 - val_loss: 0.3472 - val_accuracy: 0.9414\n",
            "Epoch 49/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0185 - accuracy: 0.9899 - val_loss: 0.3646 - val_accuracy: 0.9456\n",
            "Epoch 50/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0178 - accuracy: 0.9910 - val_loss: 0.3509 - val_accuracy: 0.9473\n",
            "Epoch 51/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0173 - accuracy: 0.9910 - val_loss: 0.3574 - val_accuracy: 0.9481\n",
            "Epoch 52/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0168 - accuracy: 0.9914 - val_loss: 0.3593 - val_accuracy: 0.9464\n",
            "Epoch 53/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0177 - accuracy: 0.9895 - val_loss: 0.3653 - val_accuracy: 0.9448\n",
            "Epoch 54/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0161 - accuracy: 0.9918 - val_loss: 0.3588 - val_accuracy: 0.9481\n",
            "Epoch 55/100\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.0156 - accuracy: 0.9916 - val_loss: 0.3745 - val_accuracy: 0.9481\n",
            "Epoch 56/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0159 - accuracy: 0.9897 - val_loss: 0.3798 - val_accuracy: 0.9431\n",
            "Epoch 57/100\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.0159 - accuracy: 0.9916 - val_loss: 0.3795 - val_accuracy: 0.9464\n",
            "Epoch 58/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0158 - accuracy: 0.9904 - val_loss: 0.3685 - val_accuracy: 0.9456\n",
            "Epoch 59/100\n",
            "150/150 [==============================] - 1s 9ms/step - loss: 0.0144 - accuracy: 0.9908 - val_loss: 0.3760 - val_accuracy: 0.9481\n",
            "Epoch 60/100\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.0148 - accuracy: 0.9914 - val_loss: 0.3696 - val_accuracy: 0.9473\n",
            "Epoch 61/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0151 - accuracy: 0.9906 - val_loss: 0.3749 - val_accuracy: 0.9481\n",
            "Epoch 62/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0149 - accuracy: 0.9906 - val_loss: 0.3836 - val_accuracy: 0.9473\n",
            "Epoch 63/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0153 - accuracy: 0.9914 - val_loss: 0.3844 - val_accuracy: 0.9481\n",
            "Epoch 64/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0151 - accuracy: 0.9904 - val_loss: 0.3935 - val_accuracy: 0.9414\n",
            "Epoch 65/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0152 - accuracy: 0.9910 - val_loss: 0.3881 - val_accuracy: 0.9423\n",
            "Epoch 66/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0144 - accuracy: 0.9906 - val_loss: 0.3952 - val_accuracy: 0.9439\n",
            "Epoch 67/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0141 - accuracy: 0.9912 - val_loss: 0.3971 - val_accuracy: 0.9456\n",
            "Epoch 68/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0139 - accuracy: 0.9918 - val_loss: 0.4077 - val_accuracy: 0.9473\n",
            "Epoch 69/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0143 - accuracy: 0.9910 - val_loss: 0.4141 - val_accuracy: 0.9456\n",
            "Epoch 70/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0137 - accuracy: 0.9914 - val_loss: 0.4091 - val_accuracy: 0.9464\n",
            "Epoch 71/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9916 - val_loss: 0.4099 - val_accuracy: 0.9473\n",
            "Epoch 72/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9916 - val_loss: 0.4111 - val_accuracy: 0.9448\n",
            "Epoch 73/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0141 - accuracy: 0.9906 - val_loss: 0.4156 - val_accuracy: 0.9448\n",
            "Epoch 74/100\n",
            "150/150 [==============================] - 2s 13ms/step - loss: 0.0133 - accuracy: 0.9910 - val_loss: 0.4206 - val_accuracy: 0.9448\n",
            "Epoch 75/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0139 - accuracy: 0.9914 - val_loss: 0.4238 - val_accuracy: 0.9439\n",
            "Epoch 76/100\n",
            "150/150 [==============================] - 1s 8ms/step - loss: 0.0136 - accuracy: 0.9906 - val_loss: 0.4131 - val_accuracy: 0.9456\n",
            "Epoch 77/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0139 - accuracy: 0.9912 - val_loss: 0.4115 - val_accuracy: 0.9464\n",
            "Epoch 78/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0133 - accuracy: 0.9920 - val_loss: 0.4214 - val_accuracy: 0.9456\n",
            "Epoch 79/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9908 - val_loss: 0.4226 - val_accuracy: 0.9473\n",
            "Epoch 80/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 0.9918 - val_loss: 0.4198 - val_accuracy: 0.9448\n",
            "Epoch 81/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0133 - accuracy: 0.9927 - val_loss: 0.4237 - val_accuracy: 0.9456\n",
            "Epoch 82/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0132 - accuracy: 0.9912 - val_loss: 0.4364 - val_accuracy: 0.9448\n",
            "Epoch 83/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0131 - accuracy: 0.9908 - val_loss: 0.4170 - val_accuracy: 0.9414\n",
            "Epoch 84/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0135 - accuracy: 0.9910 - val_loss: 0.4363 - val_accuracy: 0.9431\n",
            "Epoch 85/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9914 - val_loss: 0.4372 - val_accuracy: 0.9448\n",
            "Epoch 86/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0134 - accuracy: 0.9908 - val_loss: 0.4377 - val_accuracy: 0.9423\n",
            "Epoch 87/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0132 - accuracy: 0.9908 - val_loss: 0.4517 - val_accuracy: 0.9423\n",
            "Epoch 88/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9916 - val_loss: 0.4484 - val_accuracy: 0.9423\n",
            "Epoch 89/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0133 - accuracy: 0.9912 - val_loss: 0.4568 - val_accuracy: 0.9406\n",
            "Epoch 90/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9910 - val_loss: 0.4542 - val_accuracy: 0.9397\n",
            "Epoch 91/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9925 - val_loss: 0.4727 - val_accuracy: 0.9423\n",
            "Epoch 92/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9920 - val_loss: 0.4708 - val_accuracy: 0.9439\n",
            "Epoch 93/100\n",
            "150/150 [==============================] - 1s 7ms/step - loss: 0.0131 - accuracy: 0.9916 - val_loss: 0.4648 - val_accuracy: 0.9423\n",
            "Epoch 94/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0124 - accuracy: 0.9916 - val_loss: 0.4842 - val_accuracy: 0.9356\n",
            "Epoch 95/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0130 - accuracy: 0.9914 - val_loss: 0.4854 - val_accuracy: 0.9381\n",
            "Epoch 96/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0129 - accuracy: 0.9910 - val_loss: 0.4844 - val_accuracy: 0.9397\n",
            "Epoch 97/100\n",
            "150/150 [==============================] - 1s 6ms/step - loss: 0.0133 - accuracy: 0.9912 - val_loss: 0.4922 - val_accuracy: 0.9406\n",
            "Epoch 98/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0131 - accuracy: 0.9918 - val_loss: 0.4944 - val_accuracy: 0.9364\n",
            "Epoch 99/100\n",
            "150/150 [==============================] - 1s 5ms/step - loss: 0.0125 - accuracy: 0.9925 - val_loss: 0.5026 - val_accuracy: 0.9381\n",
            "Epoch 100/100\n",
            "150/150 [==============================] - 1s 4ms/step - loss: 0.0123 - accuracy: 0.9927 - val_loss: 0.5080 - val_accuracy: 0.9414\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "6OSVgQxBNH0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87d8d4ce-24be-47e2-c5b0-2da117b8a9d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 16)           119232    \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1600)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 15)                24015     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 80        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 143327 (559.87 KB)\n",
            "Trainable params: 143327 (559.87 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have already trained the model and have X_test_padded and y_test defined\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test_padded, y_test)\n",
        "prediction_prob = model.predict(X_test_padded)\n",
        "\n",
        "print(f'Test Loss: {loss:.4f}')\n",
        "print(f'Test Accuracy: {accuracy*100:.2f}%')\n",
        "\n",
        "print(accuracy)\n",
        "print(roc_auc_score(y_test, prediction_prob))\n",
        "\n"
      ],
      "metadata": {
        "id": "DctvL896CD_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d79d9bc2-dc08-46e2-f11a-909909685ca3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38/38 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.9414\n",
            "38/38 [==============================] - 0s 2ms/step\n",
            "Test Loss: 0.5080\n",
            "Test Accuracy: 94.14%\n",
            "0.9414225816726685\n",
            "0.9512994279340156\n"
          ]
        }
      ]
    }
  ]
}